{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd057515-4b54-446b-81ca-6cd95a406348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total vendor chunks: 11509\n",
      "Tokens in first chunk: 3\n"
     ]
    }
   ],
   "source": [
    "import difflib\n",
    "import os\n",
    "import tiktoken\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "VENDOR_DOCS_FILE = \"/Users/apoorvah/config-diff-analyzer/data/vendor_docs/arista_user_manual.txt\"\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "\n",
    "# Set up RAG (simple local embedding store)\n",
    "with open(VENDOR_DOCS_FILE) as f:\n",
    "    vendor_text = f.read()\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=100\n",
    ")\n",
    "vendor_docs = splitter.create_documents([vendor_text])\n",
    "\n",
    "# ðŸ§® Optional: Token Counter\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "def count_tokens(text):\n",
    "    return len(encoding.encode(text))\n",
    "\n",
    "print(f\"Total vendor chunks: {len(vendor_docs)}\")\n",
    "print(f\"Tokens in first chunk: {count_tokens(vendor_docs[0].page_content)}\")\n",
    "\n",
    "vectorstore = Chroma.from_documents(vendor_docs, embedding=OpenAIEmbeddings())\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "# Prompt Template\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a senior network engineer helping review changes in router configurations.\"),\n",
    "    (\"user\", \"Here is the diff between two configs:\\n\\n{diff}\\n\\nBased on the retrieved documentation:\\n{context}\\n\\n1. Summarize what has changed.\\n2. Is this safe to push live?\\n3. Does this require draining?\\n4. If unsure, what should be validated first?\\n5. What should be monitored after the change?\")\n",
    "])\n",
    "\n",
    "# Create Chain\n",
    "llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0.3)\n",
    "chain = prompt | llm | StrOutputParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67854054-979e-4ea6-b3d5-0807c9e15b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config files\n",
    "CONFIG_PATH = \"/Users/apoorvah/config-diff-analyzer/data/examples/\"\n",
    "device_config_path = \"arista_device_config.txt\"\n",
    "desired_config_path = \"arista_desired_config.txt\"\n",
    "\n",
    "with open(CONFIG_PATH + device_config_path) as f:\n",
    "    device = f.read()\n",
    "\n",
    "with open(CONFIG_PATH + desired_config_path) as f:\n",
    "    desired = f.read()\n",
    "\n",
    "# Generate Diff\n",
    "diff_lines = list(difflib.unified_diff(\n",
    "    device.splitlines(), desired.splitlines(),\n",
    "    fromfile=device, tofile=desired, lineterm=\"\"\n",
    "))\n",
    "diff_text = \"\\n\".join(diff_lines)\n",
    "\n",
    "print(\"\\n\\n\".join(diff_lines))  # Print structured diff\n",
    "\n",
    "# Retrieve context\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "retrieved_docs = retriever.get_relevant_documents(diff_text)\n",
    "context = \"\\n---\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "\n",
    "# Run Analysis\n",
    "response = chain.invoke({\"diff\": diff_text, \"context\": context})\n",
    "display(Markdown(response))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b7d8a1-26b8-4db4-82f1-ea013fa709c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d62fb6-605a-410d-8b16-2fccb08823aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
